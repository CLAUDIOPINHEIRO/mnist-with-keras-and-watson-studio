{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was generated by Watson Studio Neural Network Modeler. It uses Keras and TensorFlow and trains the neural network for the prediction of MNIST hand-written images\n",
    "\n",
    "Make sure that you have installed all python libraries as described in the import section of the script. \n",
    "\n",
    "You need also to download the pickled data sets for training, validation and test.\n",
    "\n",
    "Upon training, the model will be saved as keras_model.hdf5. On my laptop one epoch takes around 2 minutes. To get satisfactory accuracy, two or three training epochs are sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50040, 28, 28, 1)\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 50040 samples, validate on 9960 samples\n",
      "Epoch 1/1\n",
      "50040/50040 [==============================] - 126s 3ms/step - loss: 0.2271 - acc: 0.9331 - val_loss: 0.1370 - val_acc: 0.9596\n",
      "10000/10000 [==============================] - 8s 805us/step\n",
      "[0.1247664920926094, 0.9639]\n",
      "Saving the model...\n",
      "Model saved in file: ./keras_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    IBM Deep Learning (IDE) Generated Code.\n",
    "    Compatible Keras Version : 2.1\n",
    "    Tested on Python Version : 3.6.3\n",
    "'''\n",
    "\n",
    "# Choose the underlying compiler - tensorflow or theano\n",
    "import json\n",
    "import os \n",
    "\n",
    "with open(os.path.expanduser('~') + \"/.keras/keras.json\",\"r\") as f:\n",
    "    compiler_data = json.load(f)\n",
    "compiler_data[\"backend\"] = \"tensorflow\"\n",
    "compiler_data[\"image_data_format\"] = \"channels_last\"  \n",
    "with open(os.path.expanduser('~') + '/.keras/keras.json', 'w') as outfile:\n",
    "    json.dump(compiler_data, outfile)\n",
    "\n",
    "# Global variable intilization\n",
    "defined_metrics = []\n",
    "defined_loss = \"\"\n",
    "\n",
    "# import all the required packages\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import keras.regularizers as R\n",
    "import keras.constraints as C\n",
    "from keras.layers import Activation, AveragePooling2D, BatchNormalization, Convolution2D, Dense, Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load data from pickle object\n",
    "\n",
    "import pickle\n",
    "class_labels_count = 1\n",
    "with open('mnist-tf-train.pkl', 'rb') as f:\n",
    "    (train_data, train_label) = pickle.load(f)\n",
    "\n",
    "    if (len(train_data.shape) == 3): \n",
    "        if('tensorflow' == 'tensorflow'):\n",
    "            train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], train_data.shape[2], 1).astype('float32') / 255   \n",
    "        else:\n",
    "            train_data = train_data.reshape(train_data.shape[0], 1, train_data.shape[1], train_data.shape[2]).astype('float32') / 255   \n",
    "    if (len(train_label.shape) == 1) or (len(train_label.shape) == 2 and train_label.shape[1] == 1):\n",
    "        from keras.utils import np_utils\n",
    "        class_labels_count = len(set(train_label.flatten()))\n",
    "        train_label = np_utils.to_categorical(train_label, class_labels_count)\n",
    "    else:\n",
    "        class_labels_count = train_label.shape[1]\n",
    "\n",
    "val_data = []\n",
    "if('mnist-tf-valid.pkl'):\n",
    "    with open('mnist-tf-valid.pkl', 'rb') as f:\n",
    "        (val_data, val_label) = pickle.load(f)\n",
    "        if (len(val_data.shape) == 3):\n",
    "            if('tensorflow' == 'tensorflow'):\n",
    "                val_data = val_data.reshape(val_data.shape[0], val_data.shape[1], val_data.shape[2], 1).astype('float32') / 255\n",
    "            else:\n",
    "                val_data = val_data.reshape(val_data.shape[0], 1, val_data.shape[1], val_data.shape[2]).astype('float32') / 255\n",
    "        if (len(val_label.shape) == 1) or (len(val_label.shape) == 2 and val_label.shape[1] == 1):\n",
    "            from keras.utils import np_utils\n",
    "            val_label = np_utils.to_categorical(val_label, class_labels_count)\n",
    "else:\n",
    "    print('Validation set details not provided')\n",
    "  \n",
    "test_data = []\n",
    "if('mnist-tf-test.pkl'):\n",
    "    with open('mnist-tf-test.pkl', 'rb') as f:\n",
    "        (test_data, test_label) = pickle.load(f)\n",
    "        if (len(test_data.shape) == 3): \n",
    "            if('tensorflow' == 'tensorflow'):\n",
    "                test_data = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2], 1).astype('float32') / 255\n",
    "            else:\n",
    "                test_data = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2]).astype('float32') / 255\n",
    "        if (len(test_label.shape) == 1) or (len(test_label.shape) == 2 and test_label.shape[1] == 1):\n",
    "            from keras.utils import np_utils\n",
    "            test_label = np_utils.to_categorical(test_label, class_labels_count)\n",
    "else:\n",
    "    print('Test set details not provided')\n",
    "\n",
    "print(train_data.shape)\n",
    "batch_input_shape_ImageData_aa612462 = train_data.shape[1:]\n",
    "train_batch_size = 64\n",
    "\n",
    "if True:\n",
    "\n",
    "    #Input Layer\n",
    "    ImageData_aa612462 = Input(shape=batch_input_shape_ImageData_aa612462)\n",
    "    #Convolution2D Layer\n",
    "    Convolution2D_1 = Convolution2D(32, (3, 3), kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', padding = 'valid', strides = (1, 1), data_format = 'channels_last', use_bias = False, name = 'Convolution2D_4991a3b7')(ImageData_aa612462)\n",
    "    #Batch Normalization Layer\n",
    "    Convolution2D_1 = BatchNormalization(axis=3,name='bn_Convolution2D_4991a3b7')(Convolution2D_1)\n",
    "    #Rectification Linear Unit (ReLU) Activation Layer\n",
    "    ReLU_2 = Activation('relu', name = 'ReLU_ad8b7ea2')(Convolution2D_1)\n",
    "    #Pooling2D Layer\n",
    "    Pooling2D_3 = MaxPooling2D(pool_size = (2, 2), padding = 'valid', data_format = 'channels_last', strides = (2, 2), name = 'Pooling2D_96e67797')(ReLU_2)\n",
    "    #Convolution2D Layer\n",
    "    Convolution2D_4 = Convolution2D(64, (3, 3), kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', padding = 'valid', strides = (1, 1), data_format = 'channels_last', use_bias = False, name = 'Convolution2D_23a10a4b')(Pooling2D_3)\n",
    "    #Batch Normalization Layer\n",
    "    Convolution2D_4 = BatchNormalization(axis=3,name='bn_Convolution2D_23a10a4b')(Convolution2D_4)\n",
    "    #Rectification Linear Unit (ReLU) Activation Layer\n",
    "    ReLU_5 = Activation('relu', name = 'ReLU_a3561d80')(Convolution2D_4)\n",
    "    #Pooling2D Layer\n",
    "    Pooling2D_6 = MaxPooling2D(pool_size = (2, 2), padding = 'valid', data_format = 'channels_last', strides = (2, 2), name = 'Pooling2D_302b0c45')(ReLU_5)\n",
    "    #Convolution2D Layer\n",
    "    Convolution2D_7 = Convolution2D(64, (3, 3), kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', padding = 'valid', strides = (1, 1), data_format = 'channels_last', use_bias = False, name = 'Convolution2D_9080ad6c')(Pooling2D_6)\n",
    "    #Batch Normalization Layer\n",
    "    Convolution2D_7 = BatchNormalization(axis=3,name='bn_Convolution2D_9080ad6c')(Convolution2D_7)\n",
    "    #Rectification Linear Unit (ReLU) Activation Layer\n",
    "    ReLU_8 = Activation('relu', name = 'ReLU_aac1d5a9')(Convolution2D_7)\n",
    "    #Pooling2D Layer\n",
    "    Pooling2D_9 = MaxPooling2D(pool_size = (2, 2), padding = 'valid', data_format = 'channels_last', strides = (2, 2), name = 'Pooling2D_53f9ddb1')(ReLU_8)\n",
    "    #Flatten Layer\n",
    "    Flatten_10 = Flatten(name = 'Flatten_bd06de64')(Pooling2D_9)\n",
    "    #Dense or Fully Connected (FC) Layer\n",
    "    Dense_11 = Dense(10, kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', use_bias = False, name = 'Dense_d2ec2247')(Flatten_10)\n",
    "    #Softmax Activation Layer\n",
    "    Softmax_12 = Activation('softmax', name = 'Softmax_3df1783a')(Dense_11)\n",
    "    #Accuracy Metric\n",
    "    defined_metrics = ['accuracy']\n",
    "    #SigmoidCrossEntropy Loss\n",
    "    defined_loss = 'categorical_crossentropy'\n",
    "\n",
    "    # Define a keras model\n",
    "    model_inputs = [ImageData_aa612462]\n",
    "    model_outputs = [Softmax_12]\n",
    "    model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "\n",
    "    # Set the required hyperparameters    \n",
    "    num_epochs = 1\n",
    "\n",
    "    # Defining the optimizer function\n",
    "    adam_learning_rate = 0.1\n",
    "    adam_decay = 0.1\n",
    "    adam_beta_1 = 0.9\n",
    "    adam_beta_2 = 0.999\n",
    "    optimizer_fn = Adam(lr=adam_learning_rate, beta_1=adam_beta_1, beta_2=adam_beta_2, decay=adam_decay)\n",
    "\n",
    "    # performing final checks\n",
    "    if not defined_metrics:\n",
    "        defined_metrics=None\n",
    "    if not defined_loss:\n",
    "        defined_loss = 'categorical_crossentropy'\n",
    "    if \"ImageData\" == \"TextData\" and \"\" == \"Lang_Model\":\n",
    "        # adding a final Dense layer which has (vocab_length+1) units\n",
    "        layers = [l for l in model.layers]\n",
    "        for i in range(len(layers)):\n",
    "            if isinstance(layers[i], keras.layers.core.Dense) and isinstance(layers[i+1], keras.layers.core.Activation):\n",
    "                d = Dense(vocab_length+1, name = 'Dense_for_LM_' + str(i+1))(layers[i].output)\n",
    "                layers[i+1].inbound_nodes = []              # assumption: there are no merges here\n",
    "                d = layers[i+1](d)\n",
    "        model = Model(inputs=layers[0].input, outputs=layers[len(layers)-1].output)\n",
    "    \n",
    "    # Compile and train the model\n",
    "    model.compile(loss=defined_loss, optimizer=optimizer_fn, metrics=defined_metrics)\n",
    "    \n",
    "    if len(model_outputs) > 1: \n",
    "        train_label = [train_label] * len(model_outputs)\n",
    "        if len(val_data) > 0: val_label = [val_label] * len(model_outputs)\n",
    "        if len(test_data) > 0: test_label = [test_label] * len(model_outputs)\n",
    "    \n",
    "    # validate the model\n",
    "    if (len(val_data) > 0):\n",
    "        model.fit(train_data, train_label, batch_size=train_batch_size, epochs=num_epochs, verbose=1, validation_data=(val_data, val_label), shuffle=True)\n",
    "    else:\n",
    "        model.fit(train_data, train_label, batch_size=train_batch_size, epochs=num_epochs, verbose=1, shuffle=True)\n",
    "\n",
    "    # test the model\n",
    "    if (len(test_data) > 0):\n",
    "        test_scores = model.evaluate(test_data, test_label, verbose=1)\n",
    "        print(test_scores)\n",
    "\n",
    "    # saving the model\n",
    "    print('Saving the model...')\n",
    "    if 'model_result_path' not in locals() and 'model_result_path' not in globals():\n",
    "        model_result_path = \"./keras_model.hdf5\"\n",
    "    model.save(model_result_path)\n",
    "    print(\"Model saved in file: %s\" % model_result_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "Convolution2D_4991a3b7 (Conv (None, 26, 26, 32)        288       \n",
      "_________________________________________________________________\n",
      "bn_Convolution2D_4991a3b7 (B (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "ReLU_ad8b7ea2 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "Pooling2D_96e67797 (MaxPooli (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "Convolution2D_23a10a4b (Conv (None, 11, 11, 64)        18432     \n",
      "_________________________________________________________________\n",
      "bn_Convolution2D_23a10a4b (B (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "ReLU_a3561d80 (Activation)   (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "Pooling2D_302b0c45 (MaxPooli (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "Convolution2D_9080ad6c (Conv (None, 3, 3, 64)          36864     \n",
      "_________________________________________________________________\n",
      "bn_Convolution2D_9080ad6c (B (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "ReLU_aac1d5a9 (Activation)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "Pooling2D_53f9ddb1 (MaxPooli (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "Flatten_bd06de64 (Flatten)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Dense_d2ec2247 (Dense)       (None, 10)                640       \n",
      "_________________________________________________________________\n",
      "Softmax_3df1783a (Activation (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 56,864\n",
      "Trainable params: 56,544\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm using the previously saved model for the predictions. You will see \"./keras_model_3ep.hdf5\", but you can replace it with the model that has just been saved by the previous cells (./keras_model.hdf5)\n",
    "\n",
    "I'm preprocessing the image in sense to load it as grayscale, add the contrast, resize it to the MNIST-compatible size, normalize it and reshape to correspond to the model. \n",
    "\n",
    "The prediction is given as array of 10 probabilities, and the response will be based on the highest of all values.\n",
    "\n",
    "I have uploaded some examples of digits, the prediction is quite good, but not perfect. I can see it is wrong for number 7 with dash, and for the digits that are written with very thin lines. But this is the problem of the data set, which doesn't include a lot of such examples.\n",
    "\n",
    "Please change the name of the image file and test it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is  [9.8956364e-01 1.1839402e-06 4.3682227e-04 2.8984472e-05 2.9607034e-05\n",
      " 9.1047041e-05 6.0896204e-05 1.9190690e-04 4.2568150e-04 9.1702798e-03]\n",
      "This digit is: 0 with 98.95636439323425% confidence.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.load_weights('./keras_model_3ep.hdf5')\n",
    "\n",
    "imgfile = \"number0.jpg\"\n",
    "\n",
    "image = cv2.imread(imgfile,0)\n",
    "retval, image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(cv2.resize(((image-255)/255), (28, 28)))\n",
    "\n",
    "image = np.array(cv2.resize((255-image)/255, (28, 28)).reshape((1, 28, 28, 1)))\n",
    "prediction = model.predict(image)[0]\n",
    "print(\"prediction is \",prediction)\n",
    "\n",
    "predictednumber = ''\n",
    "maxprob = -1\n",
    "for n in [0,1,2,3,4,5,6,7,8,9]:\n",
    "\tif (prediction[n] > maxprob):\n",
    "\t\tpredictednumber = str(n)\n",
    "\t\tmaxprob = prediction[n]\n",
    "print('This digit is: ' + predictednumber + ' with ' + str(maxprob * 100) + '% confidence.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell below, I'm importing all necessary libraries and recreating the model, this time not to train it, but just to be able to use it for the predictions. All the rest is the same. \n",
    "\n",
    "This means that if you don't want to train the model yourself, you can just use this section to test with different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is  [9.1495043e-01 3.0186842e-04 2.0478204e-02 2.6922538e-03 2.6453764e-04\n",
      " 1.6777651e-02 2.1572770e-03 1.9313190e-02 4.8973998e-03 1.8167138e-02]\n",
      "This digit is: 0 with 91.4950430393219% confidence.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import keras.regularizers as R\n",
    "import keras.constraints as C\n",
    "from keras.layers import Activation, AveragePooling2D, BatchNormalization, Convolution2D, Dense, Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D, Input, MaxPooling2D\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "ImageData_aa612462 = Input(shape=(28,28,1))\n",
    "#Convolution2D Layer\n",
    "Convolution2D_1 = Convolution2D(32, (3, 3), kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', padding = 'valid', strides = (1, 1), data_format = 'channels_last', use_bias = False, name = 'Convolution2D_4991a3b7')(ImageData_aa612462)\n",
    "#Batch Normalization Layer\n",
    "Convolution2D_1 = BatchNormalization(axis=3,name='bn_Convolution2D_4991a3b7')(Convolution2D_1)\n",
    "#Rectification Linear Unit (ReLU) Activation Layer\n",
    "ReLU_2 = Activation('relu', name = 'ReLU_ad8b7ea2')(Convolution2D_1)\n",
    "#Pooling2D Layer\n",
    "Pooling2D_3 = MaxPooling2D(pool_size = (2, 2), padding = 'valid', data_format = 'channels_last', strides = (2, 2), name = 'Pooling2D_96e67797')(ReLU_2)\n",
    "#Convolution2D Layer\n",
    "Convolution2D_4 = Convolution2D(64, (3, 3), kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', padding = 'valid', strides = (1, 1), data_format = 'channels_last', use_bias = False, name = 'Convolution2D_23a10a4b')(Pooling2D_3)\n",
    "#Batch Normalization Layer\n",
    "Convolution2D_4 = BatchNormalization(axis=3,name='bn_Convolution2D_23a10a4b')(Convolution2D_4)\n",
    "#Rectification Linear Unit (ReLU) Activation Layer\n",
    "ReLU_5 = Activation('relu', name = 'ReLU_a3561d80')(Convolution2D_4)\n",
    "#Pooling2D Layer\n",
    "Pooling2D_6 = MaxPooling2D(pool_size = (2, 2), padding = 'valid', data_format = 'channels_last', strides = (2, 2), name = 'Pooling2D_302b0c45')(ReLU_5)\n",
    "#Convolution2D Layer\n",
    "Convolution2D_7 = Convolution2D(64, (3, 3), kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', padding = 'valid', strides = (1, 1), data_format = 'channels_last', use_bias = False, name = 'Convolution2D_9080ad6c')(Pooling2D_6)\n",
    "#Batch Normalization Layer\n",
    "Convolution2D_7 = BatchNormalization(axis=3,name='bn_Convolution2D_9080ad6c')(Convolution2D_7)\n",
    "#Rectification Linear Unit (ReLU) Activation Layer\n",
    "ReLU_8 = Activation('relu', name = 'ReLU_aac1d5a9')(Convolution2D_7)\n",
    "#Pooling2D Layer\n",
    "Pooling2D_9 = MaxPooling2D(pool_size = (2, 2), padding = 'valid', data_format = 'channels_last', strides = (2, 2), name = 'Pooling2D_53f9ddb1')(ReLU_8)\n",
    "#Flatten Layer\n",
    "Flatten_10 = Flatten(name = 'Flatten_bd06de64')(Pooling2D_9)\n",
    "#Dense or Fully Connected (FC) Layer\n",
    "Dense_11 = Dense(10, kernel_initializer = 'glorot_normal', bias_initializer = 'glorot_normal', use_bias = False, name = 'Dense_d2ec2247')(Flatten_10)\n",
    "#Softmax Activation Layer\n",
    "Softmax_12 = Activation('softmax', name = 'Softmax_3df1783a')(Dense_11)\n",
    "#Accuracy Metric\n",
    "defined_metrics = ['accuracy']\n",
    "#SigmoidCrossEntropy Loss\n",
    "defined_loss = 'categorical_crossentropy'\n",
    "\n",
    "# Define a keras model\n",
    "model_inputs = [ImageData_aa612462]\n",
    "model_outputs = [Softmax_12]\n",
    "model = Model(inputs=model_inputs, outputs=model_outputs)\n",
    "    \n",
    "model.load_weights('./keras_model.hdf5')\n",
    "\n",
    "imgfile = \"number0.jpg\"\n",
    "\n",
    "# cv2.imread(imgfile,0) this \"0\" means that the image will be loaded as grayscale\n",
    "\n",
    "image = cv2.imread(imgfile,0)\n",
    "retval, image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(cv2.resize(((image-255)/255), (28, 28)))\n",
    "\n",
    "image = np.array(cv2.resize((255-image)/255, (28, 28)).reshape((1, 28, 28, 1)))\n",
    "\n",
    "prediction = model.predict(image)[0]\n",
    "print(\"prediction is \",prediction)\n",
    "\n",
    "predictednumber = ''\n",
    "maxprob = -1\n",
    "for n in [0,1,2,3,4,5,6,7,8,9]:\n",
    "\tif (prediction[n] > maxprob):\n",
    "\t\tpredictednumber = str(n)\n",
    "\t\tmaxprob = prediction[n]\n",
    "print('This digit is: ' + predictednumber + ' with ' + str(maxprob * 100) + '% confidence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
